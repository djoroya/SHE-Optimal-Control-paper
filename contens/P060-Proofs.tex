\section{Proofs}

\subsection{SHE as a dynamical system}\label{Section3}

As we anticipated in Section \ref{Section1}, the main contribution of the present paper is to provide a novel and alternative approach to the SHE problem, based on optimal control. As we shall see, this methodology will allow us avoiding the choice of the waveform, as the optimization process selects the most convenient one in each case. 

To this end, the starting point is to rewrite the expression of the Fourier coefficients \eqref{eq:an} as the evolution of a dynamical system. This can be easily done by means of the fundamental theorem of differential calculus as follows: for all $i,j\in\mathbb{N}$, let $\alpha_i$ and $\beta_j$ be the solutions of the following Cauchy problems
\begin{align}\label{eq:Cauchy}
	\begin{cases} 
		\displaystyle\dot{\alpha_i}(\tau)  = \frac{2}{\pi}u(\tau)\cos(i\tau), & \tau\in [0,\pi) 
		\\[6pt]  
		\alpha_i(0)  = 0       
	\end{cases} \notag 
	\\
	\\
	\begin{cases} 
		\displaystyle\dot{\beta}_j(\tau)  = \frac{2}{\pi}u(\tau)\sin(j\tau), & \tau\in [0,\pi) 
		\\[6pt]  
		\beta_j(0) = 0       
	\end{cases}\notag
\end{align}
Then 
\begin{align*}
	&\alpha_i(\tau)= \frac{2}{\pi}\int_0^\tau u(\zeta) \cos(i\zeta)\,d\zeta 
	\\[5pt]
	&\beta_j(\tau) = \frac{2}{\pi}\int_0^\tau u(\zeta) \sin(j\zeta)\,d\zeta 
\end{align*}
and the Fourier coefficients \eqref{eq:an} are given by $a_i=\alpha_i(\pi)$ and $b_j=\beta_j(\pi)$.  

Let now
\begin{align*}
	\mathcal{E}_a = \{e_a^1,e_a^2,e_a^3,\dots,e_a^{N_a}\}, \quad \mathcal{E}_b = \{e_b^1,e_b^2,e_b^3,\dots,e_b^{N_b}\}    
\end{align*}
be two sets of odd numbers, and denote
\begin{align*}
	\bm{\alpha} = \{\alpha_i\}_{i\in\mathcal{E}_a}, \quad \bm{\beta} = \{\beta_j\}_{j\in\mathcal{E}_b}.
\end{align*}
Then, for any $\tau\in [0,\pi)$, we can define the vectors 
\begin{align*}
	\bm{\mathcal{D}}^\alpha(\tau) = 
	\begin{bmatrix} 
		\cos(e_a^1\tau) \\ \cos(e_a^2\tau) \\ \vdots \\ \cos(e_a^{N_a}\tau) 
	\end{bmatrix},
	\quad \bm{\mathcal{D}}^\beta(\tau) = 
	\begin{bmatrix} 
		\sin(e_b^1\tau) \\ \sin(e_b^2\tau) \\ \vdots \\ \sin(e_b^{N_b}\tau) 
	\end{bmatrix} 
\end{align*}
with $\bm{\mathcal{D}}^\beta(\tau) \in \mathbb{R}^{N_a} $ and $ \bm{\mathcal{D}}^\beta(\tau) \in \mathbb{R}^{N_b}$, and the dynamical systems \eqref{eq:Cauchy} can be rewritten in a vectorial form as:
\begin{align}\label{eq:CauchyVec}
	\begin{cases}
		\displaystyle \dot{\bm{\alpha}}(\tau) = \frac 2\pi \bm{\mathcal{D}}^\alpha(\tau) u(\tau), & \tau \in [0,\pi)
		\\[6pt]
		\bm{\alpha}(0) = 0
	\end{cases} \notag
	\\
	\\
	\begin{cases}
		\displaystyle\dot{\bm{\beta}}(\tau)  = \frac 2\pi \bm{\mathcal{D}}^\beta(\tau) u(\tau), & \tau \in [0,\pi) 
		\\[6pt]
		\bm{\beta}(0) = 0
	\end{cases}\notag 
\end{align}
Finally, compressing the notation even more, we can now denote 
\begin{align*}
	\bm{x}(\tau) = \begin{bmatrix} \bm{\alpha}(\tau) \\ \bm{\beta}(\tau) \end{bmatrix}, \quad
	\bm{\mathcal{D}}(\tau) = \begin{bmatrix} \bm{\mathcal{D}}^\alpha(\tau) \\ \bm{\mathcal{D}}^\beta(\tau) \end{bmatrix}     
\end{align*}
so that \eqref{eq:CauchyVec} becomes
\begin{align}\label{eq:CauchyCompact}
	\begin{cases}
		\displaystyle\dot{\bm{x}}(\tau) = \frac 2\pi\bm{\mathcal{D}}(\tau) u(\tau),  & \tau \in [0,\pi)
		\\[6pt]
		\bm{x}(0) = {0}
	\end{cases}
\end{align}
and the target coefficients of the SHE problem will be given by $\bm{x}_0:=[\bm{a}_T,\bm{b}_T]^\top=\bm{x}(\pi)$.

Taking into account this new formulation, as we shall see in more detail in Section \ref{Section4}, Problem \ref{pb:SHEp} can now be recast as a control one for the dynamical systems \eqref{eq:CauchyCompact}, in which we look for a control function $u(\tau)$ steering the state $\bm{x}(\tau)$ from the origin to the target $\bm{x}_0:=[\bm{a}_T,\bm{b}_T]^\top$ in time $\tau = \pi$.

Moreover, since most often control problems are designed to drive the state of a given dynamical system to an equilibrium configuration, for instance the zero state, we introduce the change of variables $\bm{x}(\tau)\mapsto \bm{x}_T - \bm{x}(\tau)$ which allows us to reverse the time in \eqref{eq:CauchyCompact}, thus obtaining 
\begin{equation}\label{eq:CauchyReversed}
    \begin{cases}
        \displaystyle\dot{\bm{x}}(\tau) = -\frac 2\pi\bm{\mathcal{D}}(\tau)u(\tau),  & \tau \in [0,\pi)
        \\[6pt]
        \bm{x}(0) = \bm{x}_0
    \end{cases},
\end{equation}
In this new configuration, the control function $u$ is now required to steer the solution of \eqref{eq:CauchyReversed} from the initial datum $\bm{x}_T$ to zero in time $\tau=\pi$. 



\subsubsection{Optimal control for SHE}\label{Section4}

In Problem \ref{pb:OCP2}, the penalization function $\mathcal L: \mathbb{R} \rightarrow \mathbb{R}$ will be chosen such that the optimal control $u^*$ only takes values in $\mathcal U$. Furthermore, the parameter $\epsilon$ should be small so that the solution minimizes the distance from the final state and the target.

Next we will study the optimality conditions of the problem, for a general $\mathcal L$, and then specify how $\mathcal L$ should be so that the optimal control $u^*$ only takes the allowed values in $\mathcal U$.

\subsection{Optimality conditions}

To write the optimality conditions of the problem we will use the Pontryagin minimum principle \cite[Chapter~2.7]{bryson1975applied}. With this purpose, it is necessary to first introduce the Hamiltonian function 
\begin{align*}\label{eq:hamil}
    H(u,\bm{p},\tau) = \epsilon \mathcal{L}(u) - \frac 2\pi\big(\bm{p}(\tau) \cdot \bm{\mathcal{D}}(\tau)\big)u(\tau),
\end{align*}
where $\bm{p}(\tau)$ is the so-called adjoint state, which is associated with the restriction imposed by the system. This vector has the same dimension of the state $\bm{x}$, so that
\begin{gather}
  \bm{x}(\tau) = \begin{bmatrix} \bm{\alpha}(\tau) \\ \bm{\beta}(\tau) \end{bmatrix} \Leftrightarrow 
  \bm{p}(\tau) = \begin{bmatrix} \bm{p}^\alpha(\tau) \\ \bm{p}^\beta(\tau) \end{bmatrix}.
\end{gather}
In what follows, we will enumerate the optimality conditions arising from the Pontryagin principle.
\begin{itemize}
    \item[1.] \textbf{Adjoint equation}: the ODE describing the evolution of the adjoint variable is given by 
    \begin{align*}
    	\dot{\bm{p}}(\tau) = -\nabla_x H(u(\tau),\bm{p}(\tau),\tau).
    \end{align*}
    In our case, since the Hamiltonian does not depend on the dynamics, we simply have
    \begin{align}\label{eq:equationP}
    	\dot{\bm{p}}(\tau) = 0,
    \end{align}
	that is, the adjoint state is constant in time.
	
	\item[2.] \textbf{Final condition of the adjoint}: As it is well-known, the adjoint equation is defined backward in time, meaning that its initial condition is actually a final one, posed at $\tau=\pi$. This final condition is given by 
    \begin{align*}
    	\bm{p}(\pi) = \nabla_{\bm{x}} \Psi(\bm{x}) = \bm{x}(\pi) - \bm{x}_T.
    \end{align*} 
	This, together with \eqref{eq:equationP}, tells us that
	\begin{align*}
		\bm{p}(\tau) = \bm{x}(\pi) - \bm{x}_T, \quad \mbox{ for all }\tau\in [0,\pi).
	\end{align*} 
    
    \item[3.] \textbf{Optimal  Waveform}: We known that 
    \begin{align*}
    	u^* = \argmin_{|u|<1} H(\tau,\bm{p}^*,u),
    \end{align*}
	so that, in this case, we can write
    \begin{gather}
        u^*(\tau) = \argmin_{|u|<1}  \left[\epsilon \mathcal{L}(u(\tau)) - \frac 2\pi \big(\bm{p}^* \cdot \bm{\mathcal{D}}(\tau)\big) u(\tau) \right].
    \end{gather}
    Therefore, this optimality condition reduces to the optimization of a function in a variable within the interval $ [- 1,1] $. 
\end{itemize}
\vspace{1em}
\begin{definition}
    Dado el problema \ref{pb:OCP2} definimos una función $\mathcal{H}_m:[-1,1]\rightarrow \mathbb{R}$ tal que:
    \begin{gather}\label{Hm}
        \mathcal{H}_m(u) = \epsilon \mathcal{L}(u) - mu  |  \forall m \in \mathbb{R}
    \end{gather}
\end{definition}
Es importante notar que la función $\mathcal{H}_m$ es el Hamiltoniano del sistema donde hemos remplazado el valor 
\begin{gather}
	[\bm{p}^* \cdot \bm{\mathcal{D}}(\tau)] = \sum_{i \in \mathcal{E}_a} p^*_\alpha \cos(i\tau) + \sum_{j \in \mathcal{E}_b} p^*_\beta \sin(j\tau) 
\end{gather}
por el parámetro $m$. De manera que el Hamiltoniano evaluado en la trayectoria óptima varía de manera continua en todo el intervalo $\tau \in [0,\pi)]$. 
%
Esta es la razón por la que el estudio de la función $\mathcal{H}_m$, una función uni-variable parametrizada por $m$ ,tiene implicaciones en el Problema \ref{pb:OCP2}.
\newline

\begin{definition}
    Dado el Problema \ref{pb:OCP2}  definimos una función $\mathcal{G}:\mathbb{R} \rightarrow [-1,1]$ tal que:
    \begin{gather}
        \mathcal{G}(m) = \argmin_{u \in [-1,1]} \mathcal{H}_m(u)
    \end{gather}
\end{definition}
\begin{definition}
    Dado el Problema \ref{pb:OCP2} definimos el conjunto $\mathcal{M}$ como:
    \begin{gather}
        \mathcal{M} = \{m \in \mathbb{R}\ | \ \mathcal{G}(m) \notin \mathcal{U} \}
    \end{gather}
\end{definition}
\subsection{Caso Binivel (Control Bang-Bang)}
El caso binivel es el que tiene como conjunto admisible de controles $\mathcal{U}= \{-1,1\}$.
\vspace{1em}

\begin{proof}[Prueba del teorema \ref{th:bang-bang}]
    Si $\mathcal{L}$ es concava en el intervalo entonces $\mathcal{H}_m$ también lo es. De manera que $G(m)$ solo puede tomar los valores $\{-1,1\}$.
\end{proof}

\subsection{Piecewise linear penalization}

In this section, we discuss how to design the penalization term $\mathcal{L}(u)$ so that the optimal control is always contained in $\mathcal{U}$. 

In more detail, we can choose the affine interpolation of a parabola $\mathcal{L}:[-1,1] \rightarrow \mathbb{R}$ as a penalization term. That is
\begin{gather}\label{PLP}
    \mathcal{L}(u) = \begin{cases}
        \big[ (u_{k+1}+u_{k}) (u-u_k) + u_k^2 \big] & \text{if }  u \in [u_k,u_{k+1}[ \\
        1 & \text{if } u = u_{N_u} 
    \end{cases} \\
    \notag \forall k \in \{1,\dots,N_u-1\}
\end{gather}
%
Nevertheless, to compute the minimum of $\mathcal{H}_m(u)$, we shall take into account that this function is not differentiable and the optimality condition then requires to work with the subdifferential $\partial\mathcal{L}(u)$, which given by
\begin{gather}
        \partial\mathcal{L}(u)= \begin{cases}
            \{u_1 + u_2  \}   & \text{if } \ u = u_1 \\
            %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
            \{u_k + u_{k+1}\}  & \text{if } \ u \in \ ]u_k,u_{k+1}[ \hspace{0.9em} \dagger\\
            %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
            [u_k+u_{k-1} ,  u_{k+1}+u_k] & \text{if} \ u = u_k \hspace{3.9em} \ddagger \\
            %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
            \{u_{N_u} + u_{N_u-1}  \} & \text{if} \ u = u_{N_u} 
       \end{cases} \\
       \notag \dagger \ \forall k \in \{1,\dots,N_u-1\} \hspace{1em}
       \notag \ddagger  \ \forall k \in \{2,\dots,N_u-1\}
\end{gather} 

Hence, we have $\partial H_m = \epsilon\partial \mathcal{L} - m$. This means that, given $m\in \mathbb{R}$, we look for $u \in [-1,1]$ minimizing $\mathcal{H}_m(u)$. It is then necessary to determine whether zero belongs to $\partial \mathcal{H}_m(u)$.

\begin{itemize}
    \item \textbf{Case 1: $m \leq \epsilon(u_1+u_2)$}: since $m$ is less than the  minimum of all subdifferentials, then zero does not belong to any of the intervals we defined. Hence, the minimum is in one of the extrema
    \begin{gather}
        \argmin_{|u| < 1} \mathcal{H}_m(u) = u_1
    \end{gather} 
    \item \textbf{Case 2: $m = \epsilon(u_{k+1}+u_k) $}: taking into account that $\forall k \in \{1,\dots,N_u-1\}$,
    \begin{gather}
        \argmin_{|u| < 1} \mathcal{H}_m(u) = [u_k,u_{k+1}[ 
    \end{gather} 
    \item \textbf{Case 3: $\epsilon(u_k+u_{k-1})<m<\epsilon(u_{k+1}+u_k)$}: taking into account that $\forall k \in \{2,\dots,N_u-1\}$,
    \begin{gather}
        \argmin_{|u| < 1} \mathcal{H}_m(u) = u_k
    \end{gather}
    \item \textbf{Case 4: $m>\epsilon(u_{N_u}+u_{N_u-1})$}:
    \begin{gather}
        \argmin_{|u| < 1} \mathcal{H}_m(u) = u_{N_u}
    \end{gather} 
\end{itemize}

In other words, only when $m = \epsilon(u_{k+1}+u_k)$ the minima of the Hamiltonian belong to an interval. For all the other values of $m\in\mathbb{R}$, these minima are contained in $\mathcal{U}$. So that under a continuous variation of $m$, Case 2 can only occur pointwise. Recalling the optimal control problem $m(\tau) = [\bm{p}(\tau) \cdot \bm{\mathcal{D}}(\tau)]$, we can notice that Case 2 corresponds to the instants $\tau$ of change of value.






\subsection{Caso Multi-nivel}
Para el caso multi nivel deben existir $m$ para los cuales $H_m$ tenga un mínimo dentro del intervalo $[-1,1]$. Además este mínimo no puede variar de manera continua con un variación de $m$.
\vspace{1em}
\begin{proposition}
    Si $\mathcal{L}$ es derivable entonces la solución del Problema \ref{pb:OCP2} no es un control digital.
\end{proposition}
\begin{proof}
    Dado que $\mathcal{L}$ es derivable en todo el intervalo $[-1,1]$ también lo es $\mathcal{H}_m$. De manera que podemos derivar la función $\mathcal{H}_m$.
    \begin{gather}
        \frac{d \mathcal{H}_m}{du} = 0 \rightarrow
        \frac{d \mathcal{L}}{du} = m
    \end{gather}
\end{proof}
\vspace{1em}
\begin{proposition}
    Si la solución del Problema \ref{pb:OCP2} es un control digital, entonces $\mathcal{M}$ es el conjunto vacio o  un conjunto finito de elementos. 
\end{proposition}
\begin{proof}

En el caso que $\mathcal{M} = \{\emptyset\}$ por definición de $\mathcal{M}$ la imagen de $\mathcal{G}(m)$ es el conjunto $\mathcal{U}$ de manera que la solución del Problema \ref{pb:OCP2} es un control digital de $\mathcal{U}$.  

Fuera del caso anterior, si suponemos que el conjunto $\mathcal{M}$ contiene algún subintervalo $\mathcal{I}_{\mathcal{M}} \subset[-1,1]$ podemos tomar    $m_1 \in \mathcal{I}_{\mathcal{M}}$ y $ m_2 = m_1 + \varepsilon \ / \ \varepsilon << 1$ de modo que se debe cumplir que $m_2 \in \mathcal{I}_{\mathcal{M}}$
\begin{equation}
    \begin{aligned}
        \mathcal{G}(m_1) = & \argmin_{u\in[-1,1]} \ [\mathcal{H}_{m_1}(u)] & \in \mathcal{U}\\
        \mathcal{G}(m_2) = & \argmin_{u\in[-1,1]} \ [\mathcal{H}_{m_1}(u) + \varepsilon u]   & \in \mathcal{U} 
    \end{aligned}      
\end{equation}

¿Eso implica que $\mathcal{U}$ tentría algún subintervalo continuo de $[-1,1]$?
$\hfill\blacksquare$.
\end{proof} 



In what follows, we will show that there are several ways of designing a penalization term $\mathcal L$ giving us digital controls.

%Para que el considerar que el control óptimo del problema solo toma valores digitales los minimos  \ref{Hm} para todo valor de $m$ de estar contenido en $\mathcal{U}$. A continuación la prueba
%\newline
%