\section{Optimal Control for SHE}\label{Section4}

Since the SHE problem is equivalent to controlling a dynamic system from the origin of coordinates to a specific point, we must formulate a control problem that solves this task but also complies with the restrictions on the values that the control can take. It is necessary to set a finite subset $ \mathcal {U} $ of the interval $ [- 1,1] $, the optimal control is such that it can only take the values allowed in the discretization. In other words, the control problem is:
\newline
\begin{problem}[OCP for SHE]\label{OCP1}
    Given two sets of odd numbers $ \mathcal {E} _a $ and $ \mathcal {E} _b $ and given the target vector $ \bm {x} _T \in \mathbb {R} ^ {N_a + N_b} $, also given a set $ \mathcal {U} $ of admissible controls, we look for the function $ u (\tau) \ | \ \tau \in [0, \pi) $ such that:
    %
    \begin{gather}
        \min_{u(\tau) \in \mathcal{U}}         
         \frac{1}{2}|| \bm{x}(\pi)  ||^2   \\
        \notag \text{suject to: } \\
        \begin{cases}
            \dot{\bm{x}}(\tau) = -\big(\frac{2}{\pi}\big)\bm{\mathcal{D}}(\tau) u(\tau)  & \tau \in [0,\pi)\\
            \bm{x}(0) = \bm{x}_0
        \end{cases}
    \end{gather}
\end{problem}
%
The solution of this control problem is complex due to the restriction on the admissible control values.
%
In order to obtain a problem that can be solved by classical control theory we can formulate the following control problem:
\newline
\begin{problem}[Regularized OCP for SHE]\label{OCP2}
    Given two sets of odd numbers $ \mathcal {E} _a $ and $ \mathcal {E} _b $ and given the target vector $ \bm {x} _T \in \mathbb {R} ^ {N_a + N_b} $, we look for the function $ |u (\tau)|<1 \ | \ \tau \in [0, \pi) $ such that:
    \begin{gather}
        \min_{|u(\tau) |<1}         
         \Bigg[ \frac{1}{2}|| \bm{x}(\pi)  ||^2  
        + \epsilon \int_0^{\pi} \mathcal{L}(u(\tau)) d\tau \Bigg]  \\
        \notag \text{suject to: } \\
        \begin{cases}
            \dot{\bm{x}}(\tau) = -\big(\frac{2}{\pi}\big)\bm{\mathcal{D}}(\tau) u(\tau)  & \tau \in [0,\pi)\\
            \bm{x}(0) = \bm{x}_0
        \end{cases}
    \end{gather}
\end{problem}
Where we will choose $ \mathcal {L}: \mathbb {R} \rightarrow \mathbb {R} $ such that the optimal control $ u^* $ only takes values in the discretization $ \mathcal {U} $ of the interval $ [- 1.1] $. Furthermore, the parameter $ \epsilon $ should be small so that the solution minimizes the distance from the final state and the target.
%
Next we will study the optimality conditions of the problem, for a general $ \mathcal {L} $ function, and then specify how $ \mathcal {L} $ should be so that the optimal control $ u ^ * $ only takes the allowed values in $ \mathcal {U} $.

\subsection{Optimality conditions}

To write the optimility conditions of the problem we will use the principle of the Pontryagin minimum \cite[Chapter~2.7]{bryson1975applied}. For them it is necessary to define the Hamiltonian of the system, which in this case is:
\begin{gather}\label{hamil}
    H(u,\bm{p},\tau) = 
    \epsilon \mathcal{L}(u) -
    \bigg(\frac{2}{\pi}\bigg)[\bm{p}^T(\tau) \cdot \bm{\mathcal{D}}(\tau)]
    u(\tau)
\end{gather}
Where the variable $ \bm{p} (\tau) $ called adjoint state is introduced, which is associated with the restriction imposed by the system. This has the same dimension of the state vector, so that
\begin{gather}
        \bm{x}(\tau) = \begin{bmatrix}
            \bm{\alpha}(\tau) \\  \bm{\beta}(\tau)
        \end{bmatrix}   \Leftrightarrow
        \bm{p}(\tau) = \begin{bmatrix}
        \bm{p}^\alpha(\tau) \\ \bm{p}^\beta(\tau)
                \end{bmatrix}
\end{gather}
In what follows, we will enumerate the optimality conditions arising from the Pontryagin principle.

\begin{enumerate}

    \item \textbf{Final condition of the adjoint}: This optimiality condition is obtained from the cost in the final time $\tau = \pi$ of the control problem in this case $ \Psi (\bm{x}) = \frac {1}{2} \| \bm{x} (\pi) - \bm{x}_T \|^2 $.
    \begin{gather}
        \bm{p}(\pi) = \nabla_{\bm{x}} \Psi(\bm{x}) =  (\bm{x} (\pi) - \bm{x}_T)
    \end{gather}
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \item \textbf{Adjoint evolution equation}: 
    \begin{gather}
        \dot{\bm{p}}(\tau) = -\nabla_x H(u(\tau),\bm{p}(\tau),\tau) = 0
    \end{gather}
    From where it can be deduced that $ \bm {p} (\tau)$ is a constant so that $ \bm {p} (\tau) = \bm {x} (\pi) - \bm { x} _T \ | \ \forall \tau \in [0, \pi) $ so from now on we will refer to it simply as $ \bm {p} $, noting that it is invariant in time.
    \item \textbf{Optimal  Waveform}: We known that $ u^* = \argmin_{|u|<1} H(\tau,\bm{p}^*,u)$, so in this case we can write:
    \begin{gather}
        u^*(\tau) = \argmin_{|u|<1}  \Big[   \epsilon \mathcal{L}(u(\tau)) - \Big(\frac{2}{\pi}\Big)
        [{\bm{p}^*}^T \cdot \bm{\mathcal{D}}(\tau)]
        u(\tau) \Big]
    \end{gather}
    Therefore, this optimality condition reduces to the optimization of a function in a variable within the interval $ [- 1,1] $. 
\end{enumerate}
%
It is important to recall that
\begin{gather}
	[{\bm{p}^*}^T \cdot \bm{\mathcal{D}}(\tau)] = \sum_{i \in \mathcal{E}_a} p^*_\alpha \cos(i\tau) + \sum_{j \in \mathcal{E}_b} p^*_\beta \sin(j\tau) 
\end{gather}
we build a function $\mathcal{H}_m: [-1,1] \rightarrow \mathbb{R}$ such that:
\begin{gather}
    \mathcal{H}_m(u) = \epsilon \mathcal{L}(u) - mu  |  \forall m \in \mathbb{R}
\end{gather}
where we replaced the term $(2/\pi)[{\bm{p}^*}^T \cdot \bm{\mathcal{D}}(\tau)]$ with a parameter $m$ which may assume all real values. In other words, the problem of designing an optimal control which may only take real values in $\mathcal{U}$ is reduced to construct a one-dimensional function with parameter $m$ whose minima are the elements in $\mathcal{U}$ for all values of $m$. 

\subsection{Piecewise linear penalization}

In this section, we discuss how to design the penalization term $\mathcal{L}(u)$ so that the optimal control is always contained in $\mathcal{U}$. 

In more detail, we can choose the affine interpolation of a parabola $\mathcal{L}:[-1,1] \rightarrow \mathbb{R}$ as a penalization term. That is
\begin{gather}\label{PLP}
    {\mathcal{L}(u)} = \begin{cases}
        \big[ (u_{k+1}+u_{k}) (u-u_k) + u_k^2 \big] & \text{if}  u \in [u_k,u_{k+1}[ \\
        1 & \text{if} \ u = u_{N_u} 
    \end{cases} \\
    \notag \forall k \in \{1,\dots,N_u-1\}
\end{gather}
%
Nevertheless, to compute the minimum of $\mathcal{H}_m(u)$, we shall take into account that this function is not differentiable and the optimality condition then requires to work with the subdifferential $\partial\mathcal{L}(u)$, which given by
\begin{gather}
        \partial\mathcal{L}(u)= \begin{cases}
            \{u_1 + u_2  \}   & \text{if} \ u = u_1 \\
            %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
            \{u_k + u_{k+1}\}  & \text{if} \ u \in \ ]u_k,u_{k+1}[ \hspace{0.9em} \dagger\\
            %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
            [u_k+u_{k-1} ,  u_{k+1}+u_k] & \text{if} \ u = u_k \hspace{3.9em} \ddagger \\
            %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
            \{u_{N_u} + u_{N_u-1}  \} & \text{if} \ u = u_{N_u} 
       \end{cases} \\
       \notag \dagger \ \forall k \in \{1,\dots,N_u-1\} \hspace{1em}
       \notag \ddagger  \ \forall k \in \{2,\dots,N_u-1\}
\end{gather} 

Hence, we have $\partial H_m = \epsilon\partial \mathcal{L} - m$. This means that, given $m\in \mathbb{R}$, we look for $u \in [-1,1]$ minimizing $\mathcal{H}_m(u)$. It is then necessary to determine whether zero belongs to $\partial \mathcal{H}_m(u)$.

\begin{itemize}
    \item \textbf{Case 1: $m \leq \epsilon(u_1+u_2)$}: since $m$ is less than the  minimum of all subdifferentials, then zero does not belong to any of the intervals we defined. Hence, the minimum is in one of the extrema
    \begin{gather}
        \argmin_{|u| < 1} \mathcal{H}_m(u) = u_1
    \end{gather} 
    \item \textbf{Case 2: $m = \epsilon(u_{k+1}+u_k) $}: taking into account that $\forall k \in \{1,\dots,N_u-1\}$,
    \begin{gather}
        \argmin_{|u| < 1} \mathcal{H}_m(u) = [u_k,u_{k+1}[ 
    \end{gather} 
    \item \textbf{Case 3: $\epsilon(u_k+u_{k-1})<m<\epsilon(u_{k+1}+u_k)$}: taking into account that $\forall k \in \{2,\dots,N_u-1\}$,
    \begin{gather}
        \argmin_{|u| < 1} \mathcal{H}_m(u) = u_k
    \end{gather}
    \item \textbf{Case 4: $m>\epsilon(u_{N_u}+u_{N_u-1})$}:
    \begin{gather}
        \argmin_{|u| < 1} \mathcal{H}_m(u) = u_{N_u}
    \end{gather} 
\end{itemize}

In other words, only when $m = \epsilon(u_{k+1}+u_k)$ the minima of the Hamiltonian belong to an interval. For all the other values of $m\in\mathbb{R}$, these minima are contained in $\mathcal{U}$. So that under a continuous variation of $m$, Case 2 can only occur pointwise. Recalling the optimal control problem $m(\tau) = [\bm{p}^T(\tau) \cdot \bm{\mathcal{D}}(\tau)]$, we can notice that Case 2 corresponds to the instants $\tau$ of change of value.