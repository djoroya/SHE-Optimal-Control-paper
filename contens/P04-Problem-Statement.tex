\section{Optimal control for SHE}\label{Section4}

As we anticipated in Section \ref{Section3}, the SHE problem is equivalent to controlling a dynamical system associated with the Fourier coefficients \eqref{eq:an}. In this section, we present a rigorous formulation of this mentioned control problem and we analyze some relevant properties. 

In what follows, for a given vector $\bm{v}\in\mathbb{R}^d$, we shall always denote by $\|\bm{v}\|$ the euclidean norm $\|\bm{v}\|_{\mathbb{R}^d}$.
\newline


\begin{problem}[OCP for SHE]\label{pb:OCP1}
Let $\mathcal U$ be defined as in \eqref{eq:Udef}. Given two sets of odd numbers $\mathcal {E}_a $ and $\mathcal {E}_b $ with cardinality $N_a$ and $N_b$, respectively, and given the target $\bm{x}_T\in \mathbb{R}^{N_a+N_b}$, we look for the function $u(\tau):[0,\pi)\to \mathcal U$ solution of the optimal control problem  
\begin{align*}
	&\min_{u \in \mathcal{U}}\;\frac 12 \|\bm{x}(\pi)\|^2
	\\
    &\notag \text{subject to: }\quad \begin{cases}
            \displaystyle \dot{\bm{x}}(\tau) = -\frac 2\pi\bm{\mathcal{D}}(\tau) u(\tau),  & \tau \in [0,\pi)\\[6pt]
            \bm{x}(0) = \bm{x}_0
    \end{cases}
    \end{align*}
\end{problem}
The solution of Problem \ref{pb:OCP1} may be quite complex to be obtained, due to the restriction on the admissible control values. 

\begin{definition}[Digital control]
A control $u(\tau)$ is called digital if, for each time $\tau\geq 0$, it only takes values in the finite set of real number $\mathcal{U}$.  
\end{definition}



In order to bypass this difficulty, following a standard optimal control approach, we can formulate an equivalent minimization problem in which, instead of looking for $u\in\mathcal U$, we simply require that $|u|<1$ and we introduce a penalization term to ensure that $u$ is a piece-wise constant function (\textcolor{red}{digital control}). This alternative optimal control problem, which can be solved more easily by employing standard tools, reads as follows:
\newline
\begin{problem}[Penalized OCP for SHE]\label{pb:OCP2}
Fix $\epsilon>0$. Given two sets of odd numbers $\mathcal E_a $ and $\mathcal E_b $ and the target $\bm{x}_T \in \mathbb {R}^{N_a + N_b}$, we look for the  function $u:[0,\pi)\to\mathcal U$ as the solution of:
\begin{align*}
	&\min_{|u|<1} \Bigg[\Psi(\bm{x}) + \epsilon \int_0^{\pi} \mathcal{L}(u(\tau)) d\tau \Bigg]  
	\\[5pt]
	&\Psi(\bm{x}) = \frac 12 \|\bm{x}(\pi) - \bm{x}_T\|^2,
\end{align*}
under the dynamics given by \eqref{eq:CauchyReversed}.
\end{problem}

In Problem \ref{pb:OCP2}, the penalization function $\mathcal L: \mathbb{R} \rightarrow \mathbb{R}$ will be chosen such that the optimal control $u^*$ only takes values in $\mathcal U$. Furthermore, the parameter $\epsilon$ should be small so that the solution minimizes the distance from the final state and the target.

Next we will study the optimality conditions of the problem, for a general $\mathcal L$, and then specify how $\mathcal L$ should be so that the optimal control $u^*$ only takes the allowed values in $\mathcal U$.

\subsection{Optimality conditions}

To write the optimality conditions of the problem we will use the Pontryagin minimum principle \cite[Chapter~2.7]{bryson1975applied}. With this purpose, it is necessary to first introduce the Hamiltonian function 
\begin{align*}\label{eq:hamil}
    H(u,\bm{p},\tau) = \epsilon \mathcal{L}(u) - \frac 2\pi\big(\bm{p}(\tau) \cdot \bm{\mathcal{D}}(\tau)\big)u(\tau),
\end{align*}
where $\bm{p}(\tau)$ is the so-called adjoint state, which is associated with the restriction imposed by the system. This vector has the same dimension of the state $\bm{x}$, so that
\begin{gather}
  \bm{x}(\tau) = \begin{bmatrix} \bm{\alpha}(\tau) \\ \bm{\beta}(\tau) \end{bmatrix} \Leftrightarrow 
  \bm{p}(\tau) = \begin{bmatrix} \bm{p}^\alpha(\tau) \\ \bm{p}^\beta(\tau) \end{bmatrix}.
\end{gather}
In what follows, we will enumerate the optimality conditions arising from the Pontryagin principle.
\begin{itemize}
    \item[1.] \textbf{Adjoint equation}: the ODE describing the evolution of the adjoint variable is given by 
    \begin{align*}
    	\dot{\bm{p}}(\tau) = -\nabla_x H(u(\tau),\bm{p}(\tau),\tau).
    \end{align*}
    In our case, since the Hamiltonian does not depend on the dynamics, we simply have
    \begin{align}\label{eq:equationP}
    	\dot{\bm{p}}(\tau) = 0,
    \end{align}
	that is, the adjoint state is constant in time.
	
	\item[2.] \textbf{Final condition of the adjoint}: As it is well-known, the adjoint equation is defined backward in time, meaning that its initial condition is actually a final one, posed at $\tau=\pi$. This final condition is given by 
    \begin{align*}
    	\bm{p}(\pi) = \nabla_{\bm{x}} \Psi(\bm{x}) = \bm{x}(\pi) - \bm{x}_T.
    \end{align*} 
	This, together with \eqref{eq:equationP}, tells us that
	\begin{align*}
		\bm{p}(\tau) = \bm{x}(\pi) - \bm{x}_T, \quad \mbox{ for all }\tau\in [0,\pi).
	\end{align*} 
    
    \item[3.] \textbf{Optimal  Waveform}: We known that 
    \begin{align*}
    	u^* = \argmin_{|u|<1} H(\tau,\bm{p}^*,u),
    \end{align*}
	so that, in this case, we can write
    \begin{gather}
        u^*(\tau) = \argmin_{|u|<1}  \left[\epsilon \mathcal{L}(u(\tau)) - \frac 2\pi \big(\bm{p}^* \cdot \bm{\mathcal{D}}(\tau)\big) u(\tau) \right].
    \end{gather}
    Therefore, this optimality condition reduces to the optimization of a function in a variable within the interval $ [- 1,1] $. 
\end{itemize}
%\newline
\begin{proposition}
    Consideramos el problema de control \ref{pb:OCP2}, una función $\mathcal{H}_m:\mathbb{R}\rightarrow \mathbb{R}$ tal que:
    \begin{gather}\label{Hm}
        \mathcal{H}_m(u) = \epsilon \mathcal{L}(u) - mu  |  \forall m \in \mathbb{R}
    \end{gather}
    De manera que si el conjunto de todos los posibles mínimos de $\mathcal{H}_m \ | \ \forall m \in \mathbb{R} - \mathcal{M}$  es igual al conjunto $\mathcal{U}$ entonces la solución del problema \ref{pb:OCP2} es un control digital. Donde $\mathcal{M}$ es un conjunto finito de número reales donde el Hamiltoniano $\mathcal{H}_m$ podría tomar valores que no pertenezcan a $\mathcal{U}$.
\end{proposition}

\begin{proof}
    %
Es importante notar que la función $\mathcal{H}_m$ es el Hamiltoniano del sistema donde hemos remplazado el valor 
\begin{gather}
	[\bm{p}^* \cdot \bm{\mathcal{D}}(\tau)] = \sum_{i \in \mathcal{E}_a} p^*_\alpha \cos(i\tau) + \sum_{j \in \mathcal{E}_b} p^*_\beta \sin(j\tau) 
\end{gather}
por el parámetro $m$. De manera que el Hamiltoniano evaluado en la trayectoria óptima varía de manera continua en todo el intervalo $\tau \in [0,\pi)]$. Entonces en el caso de que el $m = (2/\pi)[\bm{p}^* \cdot \bm{\mathcal{D}}(\tau)] \notin \mathcal{M}$, por hipótesis el mínimo de $H_m$ esta en $\mathcal{U}$. En el caso contrario, $m = (2/\pi)[\bm{p}^* \cdot \bm{\mathcal{D}}(\tau)] \in \mathcal{M}$  

\end{proof}
Where we replaced the term $(2/\pi)[\bm{p}^* \cdot \bm{\mathcal{D}}(\tau)]$ with a parameter $m$ which may assume all real values. The problem of designing an optimal control which may only take real values in $\mathcal{U}$ is reduced to construct a one-dimensional function with parameter $m$ whose minima are the elements in $\mathcal{U}$ for all values of $m$.

\subsection{Sufficient conditions to obtain digital control}

In what follows, we will show that there are several ways of designing a penalization term $\mathcal L$ giving us digital controls.
\newline
\begin{theorem}
Assume that the finite set $\mathcal{U}$ defined in \eqref{eq:Udef} is composed by elements in ascending order. Let $\mathcal{Y} = \{y_\ell\}_{\ell=1}^L$ be another finite set, with the same cardinality as $\mathcal U$, such that the sequence $d\mathcal{Y} = \{y_\ell - y_{\ell+1}\}_{\ell=1}^{L-1}$ is monotone. Let $\mathcal{L}:\mathbb{R} \rightarrow \mathbb{R}$ be a piece-wise continuous function en los intervalos $\{ [u_l,u_{l+1})\}_{l=1}^L$ de manera que $\{y_l = \mathcal{L}(u_l)\}_{l=1}^L$. Si la funciones definidas entre cada intervalo $\{[u_l,u_{l+1}]\}_{l=1}^L$ son concavas, entonces la penalización $\mathcal{L}$ en el problema \ref{pb:OCP2} da lugar a un control que solo toma valores en $\mathcal{U}$.
\end{theorem}
Para que el considerar que el control óptimo del problema solo toma valores digitales los minimos  \ref{Hm} para todo valor de $m$ de estar contenido en $\mathcal{U}$. A continuación la prueba
\newline

\begin{proof}
    Teniendo en cuenta que la función 
\end{proof}

\subsection{Piecewise linear penalization}

In this section, we discuss how to design the penalization term $\mathcal{L}(u)$ so that the optimal control is always contained in $\mathcal{U}$. 

In more detail, we can choose the affine interpolation of a parabola $\mathcal{L}:[-1,1] \rightarrow \mathbb{R}$ as a penalization term. That is
\begin{gather}\label{PLP}
    \mathcal{L}(u) = \begin{cases}
        \big[ (u_{k+1}+u_{k}) (u-u_k) + u_k^2 \big] & \text{if }  u \in [u_k,u_{k+1}[ \\
        1 & \text{if } u = u_{N_u} 
    \end{cases} \\
    \notag \forall k \in \{1,\dots,N_u-1\}
\end{gather}
%
Nevertheless, to compute the minimum of $\mathcal{H}_m(u)$, we shall take into account that this function is not differentiable and the optimality condition then requires to work with the subdifferential $\partial\mathcal{L}(u)$, which given by
\begin{gather}
        \partial\mathcal{L}(u)= \begin{cases}
            \{u_1 + u_2  \}   & \text{if } \ u = u_1 \\
            %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
            \{u_k + u_{k+1}\}  & \text{if } \ u \in \ ]u_k,u_{k+1}[ \hspace{0.9em} \dagger\\
            %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
            [u_k+u_{k-1} ,  u_{k+1}+u_k] & \text{if} \ u = u_k \hspace{3.9em} \ddagger \\
            %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
            \{u_{N_u} + u_{N_u-1}  \} & \text{if} \ u = u_{N_u} 
       \end{cases} \\
       \notag \dagger \ \forall k \in \{1,\dots,N_u-1\} \hspace{1em}
       \notag \ddagger  \ \forall k \in \{2,\dots,N_u-1\}
\end{gather} 

Hence, we have $\partial H_m = \epsilon\partial \mathcal{L} - m$. This means that, given $m\in \mathbb{R}$, we look for $u \in [-1,1]$ minimizing $\mathcal{H}_m(u)$. It is then necessary to determine whether zero belongs to $\partial \mathcal{H}_m(u)$.

\begin{itemize}
    \item \textbf{Case 1: $m \leq \epsilon(u_1+u_2)$}: since $m$ is less than the  minimum of all subdifferentials, then zero does not belong to any of the intervals we defined. Hence, the minimum is in one of the extrema
    \begin{gather}
        \argmin_{|u| < 1} \mathcal{H}_m(u) = u_1
    \end{gather} 
    \item \textbf{Case 2: $m = \epsilon(u_{k+1}+u_k) $}: taking into account that $\forall k \in \{1,\dots,N_u-1\}$,
    \begin{gather}
        \argmin_{|u| < 1} \mathcal{H}_m(u) = [u_k,u_{k+1}[ 
    \end{gather} 
    \item \textbf{Case 3: $\epsilon(u_k+u_{k-1})<m<\epsilon(u_{k+1}+u_k)$}: taking into account that $\forall k \in \{2,\dots,N_u-1\}$,
    \begin{gather}
        \argmin_{|u| < 1} \mathcal{H}_m(u) = u_k
    \end{gather}
    \item \textbf{Case 4: $m>\epsilon(u_{N_u}+u_{N_u-1})$}:
    \begin{gather}
        \argmin_{|u| < 1} \mathcal{H}_m(u) = u_{N_u}
    \end{gather} 
\end{itemize}

In other words, only when $m = \epsilon(u_{k+1}+u_k)$ the minima of the Hamiltonian belong to an interval. For all the other values of $m\in\mathbb{R}$, these minima are contained in $\mathcal{U}$. So that under a continuous variation of $m$, Case 2 can only occur pointwise. Recalling the optimal control problem $m(\tau) = [\bm{p}(\tau) \cdot \bm{\mathcal{D}}(\tau)]$, we can notice that Case 2 corresponds to the instants $\tau$ of change of value.