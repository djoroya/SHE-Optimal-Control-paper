
\subsection{Proof of Propsition \ref{prop:Hamiltoniano} (Hamiltonian Function)}\label{proof:Hamiltoniano}

Para demostrar porque la función Hamiltoniano caracteriza el problema de control, es necesario analizar las condiciones de optimialidad. Utilizaremos el principio del mímimo de Pontryagin \cite[Chapter~2.7]{bryson1975applied}.

\subsubsection{Optimality conditions}

First, we introduce the Hamiltonian function 
\begin{align*}\label{eq:hamil}
    \mathcal{H}(u,\bm{p},\tau) = \epsilon \mathcal{L}(u) - \frac 2\pi\big(\bm{p}(\tau) \cdot \bm{\mathcal{D}}(\tau)\big)u(\tau),
\end{align*}
where $\bm{p}(\tau)$ is the so-called adjoint state, which is associated with the restriction imposed by the system \eqref{eq:CauchyReversed}. This vector has the same dimension of the state $\bm{x}$, so that
\begin{gather}
  \bm{x}(\tau) = \begin{bmatrix} \bm{\alpha}(\tau) \\ \bm{\beta}(\tau) \end{bmatrix} \Leftrightarrow 
  \bm{p}(\tau) = \begin{bmatrix} \bm{p}^\alpha(\tau) \\ \bm{p}^\beta(\tau) \end{bmatrix}.
\end{gather}
In what follows, we will enumerate the optimality conditions arising from the Pontryagin principle.
\begin{itemize}
    \item[1.] \textbf{Adjoint system}: the ODE describing the evolution of the adjoint variable is given by 
    \begin{align*}
    	\dot{\bm{p}}(\tau) = -\nabla_x \mathcal{H}(u(\tau),\bm{p}(\tau),\tau).
    \end{align*}
    In our case, since the Hamiltonian does not depend on the dynamics, we simply have
    \begin{align}\label{eq:equationP}
    	\dot{\bm{p}}(\tau) = 0,
    \end{align}
	that is, the adjoint state is constant in time.
	
	\item[2.] \textbf{Final condition of the adjoint system}: As it is well-known, the adjoint equation is defined backward in time, meaning that its initial condition is actually a final one, posed at $\tau=\pi$. This final condition is given by 
    \begin{align*}
    	\bm{p}(\pi) = | \nabla_{\bm{x}} \Psi(\bm{x}) |_{\bm{x} = \pi}
    \end{align*} 
    Where final cost $\Psi(\bm{x})$ in our case is $\Psi(\bm{x}) = \frac{1}{2}||\bm{x}||^2$, so  we can obtain:
    \begin{gather}
        \bm{p}(\pi) = \bm{x}(\pi)
    \end{gather}
	This, together with \eqref{eq:equationP}, tells us that
	\begin{align*}
		\bm{p}(\tau) = \bm{x}(\pi), \quad \mbox{ for all }\tau\in [0,\pi).
	\end{align*} 
    
    \item[3.] \textbf{Optimal  Control}: We known that 
    \begin{align*}
    	u^* = \argmin_{|u|<1} H(\tau,\bm{p}^*,u),
    \end{align*}
	so that, in this case, we can write
    \begin{gather}
        u^*(\tau) = \argmin_{|u|<1}  \left[\epsilon \mathcal{L}(u(\tau)) - \frac 2\pi \big(\bm{p}^* \cdot \bm{\mathcal{D}}(\tau)\big) u(\tau) \right].
    \end{gather}
\end{itemize}

Therefore, this optimality condition reduces to the optimization of a function in a variable within the interval $ [- 1,1] $. It important note that the function $\mathcal{H}_m$ (Definition \ref{def:Hamiltonian}) is the Hamiltonian of system where we have replaced: 
\begin{gather}
	[\bm{p}^* \cdot \bm{\mathcal{D}}(\tau)] = \sum_{i \in \mathcal{E}_a} p^*_\alpha \cos(i\tau) + \sum_{j \in \mathcal{E}_b} p^*_\beta \sin(j\tau) 
\end{gather}
for parameter $m$. 
%
De manera que el Hamiltoniano evaluado en la trayectoria óptima varía de manera continua en todo el intervalo $\tau \in [0,\pi)]$. Es decir, si casi todo $m = [\bm{p}^* \cdot \bm{\mathcal{D}}(\tau)]$ los mímimos del Hamiltoniano solo estan en $\mathcal{U}$ entonces el control óptimo solo podrá tomar los valores contenidos en $\mathcal{U}$. El conjunto de valores de $m = [\bm{p}^* \cdot \bm{\mathcal{D}}(\tau)]$  tal que $u^*$ no esta en $\mathcal{U}$ deberán ser puntos en $\mathcal{R}$ de manera que eso solo pueda suceder en instantes de tiempo concreto. Estos instantes de tiempos son los tiempos de cambio de valor.

